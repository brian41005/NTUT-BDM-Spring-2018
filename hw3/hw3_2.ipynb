{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 103590450 馬茂源 四資四"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T14:56:54.896100Z",
     "start_time": "2018-05-02T14:56:54.478992Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "import string\n",
    "import html\n",
    "import hashlib\n",
    "import re\n",
    "from collections import defaultdict\n",
    "import itertools\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T14:56:54.898607Z",
     "start_time": "2018-05-02T14:56:54.896602Z"
    }
   },
   "outputs": [],
   "source": [
    "t0 = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T14:56:54.907130Z",
     "start_time": "2018-05-02T14:56:54.899610Z"
    }
   },
   "outputs": [],
   "source": [
    "if not os.path.exists('result'):\n",
    "    os.mkdir('result')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T14:56:54.913647Z",
     "start_time": "2018-05-02T14:56:54.908635Z"
    }
   },
   "outputs": [],
   "source": [
    "file_names = ['./data/reut2-{0:0>3}.sgm'.format(i) for i in range(22)]\n",
    "# file_names = [file_names[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1) Given the Reuters-21578 dataset, please calculate all kshingles and output the set representation of the text dataset as a matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T14:56:54.922169Z",
     "start_time": "2018-05-02T14:56:54.914650Z"
    }
   },
   "outputs": [],
   "source": [
    "def parser(file_name):\n",
    "    with open(file_name, 'r', encoding='ISO-8859-1') as f:\n",
    "        file = f.read()\n",
    "    news = []\n",
    "    start = 0\n",
    "    for i in range(len(file)):\n",
    "        if file[i:i+6] == '<BODY>':\n",
    "            start = i+6\n",
    "        elif file[i:i+7] == '</BODY>':\n",
    "            n = file[start:i].replace('\\n', ' ')\n",
    "            n = n.replace('REUTER &#3;', '')\n",
    "            news.append(n)\n",
    "    return news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T14:57:00.150591Z",
     "start_time": "2018-05-02T14:56:54.923172Z"
    }
   },
   "outputs": [],
   "source": [
    "news = []\n",
    "for i in file_names:\n",
    "    each_news = parser(i) \n",
    "    news.extend(each_news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T14:57:00.157611Z",
     "start_time": "2018-05-02T14:57:00.150591Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19043"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T14:57:00.164629Z",
     "start_time": "2018-05-02T14:57:00.158614Z"
    }
   },
   "outputs": [],
   "source": [
    "news_data = pd.DataFrame(data=news, columns=['news'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T14:57:00.177664Z",
     "start_time": "2018-05-02T14:57:00.165631Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>news</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Showers continued throughout the week in the B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Standard Oil Co and BP North America Inc said ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Texas Commerce Bancshares Inc's Texas Commerce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BankAmerica Corp is not under pressure to act ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The U.S. Agriculture Department reported the f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                news\n",
       "0  Showers continued throughout the week in the B...\n",
       "1  Standard Oil Co and BP North America Inc said ...\n",
       "2  Texas Commerce Bancshares Inc's Texas Commerce...\n",
       "3  BankAmerica Corp is not under pressure to act ...\n",
       "4  The U.S. Agriculture Department reported the f..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T14:57:00.184683Z",
     "start_time": "2018-05-02T14:57:00.178667Z"
    }
   },
   "outputs": [],
   "source": [
    "def tokenizer(text):\n",
    "    strip_chars = '.' + ' –…' + string.punctuation\n",
    "    text = html.unescape(text)\n",
    "    text = text.lower()\n",
    "    text = text.strip(strip_chars)\n",
    "    text = text.replace('reuter', '')\n",
    "    text = re.sub(re.compile('<.*?>'), '', text)\n",
    "    return re.findall(r'\\w+', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T14:57:00.193706Z",
     "start_time": "2018-05-02T14:57:00.185686Z"
    }
   },
   "outputs": [],
   "source": [
    "test_news = news_data['news'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T14:57:00.200725Z",
     "start_time": "2018-05-02T14:57:00.194710Z"
    }
   },
   "outputs": [],
   "source": [
    "#tokenizer(test_news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T14:57:01.163798Z",
     "start_time": "2018-05-02T14:57:00.201727Z"
    }
   },
   "outputs": [],
   "source": [
    "news_data['news_token'] = news_data.apply(lambda x: tokenizer(x['news']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T14:57:01.168310Z",
     "start_time": "2018-05-02T14:57:01.164801Z"
    }
   },
   "outputs": [],
   "source": [
    "def k_shingle(text, k):\n",
    "    string = ' '.join(text)\n",
    "    shingles = set([])\n",
    "    for i in range(len(string)-k + 1):\n",
    "        shingles.add(string[i:i+k])\n",
    "    return (shingles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T14:57:04.083057Z",
     "start_time": "2018-05-02T14:57:01.169314Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19043, 1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_token = news_data['news_token'].apply(lambda x: k_shingle(x, 5)).values.reshape(-1, 1)\n",
    "news_token.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T14:57:04.820026Z",
     "start_time": "2018-05-02T14:57:04.084060Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "273798"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shingles = set([])\n",
    "for s in news_token:\n",
    "    shingles |= s[0]\n",
    "shingles = list(shingles)\n",
    "len(shingles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T14:57:04.886703Z",
     "start_time": "2018-05-02T14:57:04.821029Z"
    }
   },
   "outputs": [],
   "source": [
    "shingles_dict_ = {s:i for i, s in enumerate(shingles)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T14:57:04.891216Z",
     "start_time": "2018-05-02T14:57:04.887707Z"
    }
   },
   "outputs": [],
   "source": [
    "def encode_shingles(row, shingles_dict_):\n",
    "    v = np.zeros(len(shingles_dict_), dtype='int')\n",
    "    row = row[0]\n",
    "    v[[shingles_dict_[r] for r in row]] = 1\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T14:57:21.608699Z",
     "start_time": "2018-05-02T14:57:04.892720Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19043, 273798)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shingles = np.apply_along_axis(encode_shingles, 1, news_token, shingles_dict_=shingles_dict_)\n",
    "shingles.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T14:57:21.612209Z",
     "start_time": "2018-05-02T14:57:21.610204Z"
    }
   },
   "outputs": [],
   "source": [
    "# with open('result/task_1.csv', 'w') as f:\n",
    "#     for r in shingles:\n",
    "#         f.write(','.join([i for i in r.astype('str')])+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T14:57:21.627750Z",
     "start_time": "2018-05-02T14:57:21.613211Z"
    }
   },
   "outputs": [],
   "source": [
    "np.savetxt(\"result/task_1.csv\", shingles.T[:100, :100], delimiter=',', fmt='%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2) Given the set representation, compute the minhash signatures of all documents using MapReduce."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T14:57:21.631260Z",
     "start_time": "2018-05-02T14:57:21.628754Z"
    }
   },
   "outputs": [],
   "source": [
    "news_shingles = shingles.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T14:57:21.644795Z",
     "start_time": "2018-05-02T14:57:21.633267Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_prime(greater_than):   \n",
    "    def is_prime(n):\n",
    "        if n % 2 == 0 and n > 2: \n",
    "            return False\n",
    "        return all(n % i for i in range(3, int(np.sqrt(n)) + 1, 2))\n",
    "    is_p = False\n",
    "    \n",
    "    while not is_p:\n",
    "        greater_than += 1\n",
    "        is_p = is_prime(greater_than)\n",
    "        \n",
    "    return greater_than"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T14:57:21.653319Z",
     "start_time": "2018-05-02T14:57:21.646300Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_hash_func_list(n, k=100):\n",
    "    p = get_prime(n)\n",
    "    func_list = []\n",
    "    for a, b in zip(np.random.randint(0, n, size=k),\n",
    "                   np.random.randint(0, n, size=k)):\n",
    "        func_list.append(lambda x, a=a,b=b,p=p,n=n: ((a*x+b)%p)%n)\n",
    "    return np.array(func_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T14:57:21.666855Z",
     "start_time": "2018-05-02T14:57:21.654321Z"
    }
   },
   "outputs": [],
   "source": [
    "def one_pass_minhashing(shingles, k=100):\n",
    "    n = shingles.shape[0]\n",
    "    hash_list = get_hash_func_list(n, k=k)\n",
    "    singnature = np.full((k, shingles.shape[1]), fill_value=np.inf)\n",
    "    \n",
    "    for i in range(n):\n",
    "        hash_value = np.array([h(i) for h in hash_list])\n",
    "\n",
    "        for j, c in enumerate(shingles[i, :] == 1):\n",
    "            if c:\n",
    "                mask = singnature[:, j] > hash_value\n",
    "                singnature[:, j][mask] = hash_value[mask]\n",
    "    \n",
    "    return singnature.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T14:57:21.677883Z",
     "start_time": "2018-05-02T14:57:21.668859Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4, 4, 4, 4],\n",
       "       [0, 0, 0, 0],\n",
       "       [1, 1, 1, 1],\n",
       "       [0, 0, 2, 0],\n",
       "       [0, 0, 2, 0],\n",
       "       [0, 0, 0, 0]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_input = np.array([[1,0,1,0],\n",
    "                       [1,0,0,1],\n",
    "                       [0,1,0,1],\n",
    "                       [0,1,0,1],\n",
    "                       [0,1,0,1],\n",
    "                       [1,0,1,0],\n",
    "                       [1,0,1,0]])\n",
    "test_singnature = one_pass_minhashing(test_input, k=6)\n",
    "test_singnature.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T15:02:35.072512Z",
     "start_time": "2018-05-02T14:57:21.679388Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python36\\lib\\site-packages\\ipykernel_launcher.py:6: RuntimeWarning: overflow encountered in long_scalars\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "singnature = one_pass_minhashing(news_shingles, k=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T15:02:35.077023Z",
     "start_time": "2018-05-02T15:02:35.074016Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 19043)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "singnature.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T15:02:35.085546Z",
     "start_time": "2018-05-02T15:02:35.078027Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int32')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "singnature.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T15:02:35.407903Z",
     "start_time": "2018-05-02T15:02:35.086549Z"
    }
   },
   "outputs": [],
   "source": [
    "np.savetxt(\"result/task_2.csv\", singnature, delimiter=\",\",  fmt='%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (3) Implement the LSH algorithm by MapReduce and output the resulting candidate pairs of similar documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T15:02:35.412415Z",
     "start_time": "2018-05-02T15:02:35.409408Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sha1 HASH object @ 0x000002621260AEE0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hashlib.sha1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T15:02:35.423946Z",
     "start_time": "2018-05-02T15:02:35.414421Z"
    }
   },
   "outputs": [],
   "source": [
    "def LSH(singnature, b=20):\n",
    "    buckets = [defaultdict(set) for i in range(b)]\n",
    "    k = singnature.shape[0]\n",
    "    r = k // b\n",
    "    for i, doc in enumerate(singnature.T):\n",
    "        x = np.array2string(doc.astype('int'), separator='', precision=0)\n",
    "        for j, start_idx in enumerate(range(0, k, r)):\n",
    "            #print(j, j+r)\n",
    "            key = hashlib.sha1(x[start_idx:start_idx+r].encode()).hexdigest()\n",
    "            buckets[j][key].add(i)\n",
    "    return buckets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T15:02:35.431466Z",
     "start_time": "2018-05-02T15:02:35.425451Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_distance(s1, s2):\n",
    "    intersection = (s1-s2).astype('int')\n",
    "    return 1 - (intersection.sum() / intersection.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T15:02:35.442997Z",
     "start_time": "2018-05-02T15:02:35.432469Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_candidate(buckets):\n",
    "    candidates = set([])\n",
    "    for bucket in buckets:\n",
    "        for k, items in bucket.items():\n",
    "            if len(items) > 1 and len(items) < 100:\n",
    "                pairs = itertools.combinations(items, 2)\n",
    "                for p in pairs:\n",
    "                    if p in candidates:\n",
    "                        continue\n",
    "                        \n",
    "                    if get_distance(singnature[:, p[0]], \n",
    "                                    singnature[:, p[1]]) >= 0.8: \n",
    "                        candidates.add(p)\n",
    "\n",
    "    return candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T15:02:38.998446Z",
     "start_time": "2018-05-02T15:02:35.445003Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "buckets = LSH(singnature, b=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T15:02:39.001455Z",
     "start_time": "2018-05-02T15:02:38.999449Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for bucket in buckets:\n",
    "#     print(len(bucket))\n",
    "#     for _, items in bucket.items():\n",
    "#         if len(items) > 1 and len(items) < 10000:\n",
    "#             print('\\t', len(items), end=' ')\n",
    "#             print(len(list(itertools.combinations(items, 2))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T15:02:51.410938Z",
     "start_time": "2018-05-02T15:02:39.002959Z"
    }
   },
   "outputs": [],
   "source": [
    "candidates = get_candidate(buckets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T15:02:51.466585Z",
     "start_time": "2018-05-02T15:02:51.411439Z"
    }
   },
   "outputs": [],
   "source": [
    "candidates = list(candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T15:02:51.475109Z",
     "start_time": "2018-05-02T15:02:51.467589Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1174935"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T15:03:27.734984Z",
     "start_time": "2018-05-02T15:03:27.731475Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(107, 11120),\n",
       " (10978, 14704),\n",
       " (4806, 14311),\n",
       " (11913, 1870),\n",
       " (5322, 18769),\n",
       " (7969, 5943),\n",
       " (2044, 2237),\n",
       " (11551, 16750),\n",
       " (12404, 4385),\n",
       " (7179, 15734)]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidates[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T15:03:40.415688Z",
     "start_time": "2018-05-02T15:03:40.350014Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "candidates.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T15:03:40.735539Z",
     "start_time": "2018-05-02T15:03:40.416190Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('result/task_3.csv', 'w') as f:\n",
    "    for i, g in itertools.groupby(candidates, key=lambda x: x[0]):\n",
    "        f.write('%5d, %s\\n'%(i, str(list(i[1] for i in g))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T15:03:40.738547Z",
     "start_time": "2018-05-02T15:03:40.736541Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#news_data.loc[new_candidates[0][0]]['news']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T15:03:40.746568Z",
     "start_time": "2018-05-02T15:03:40.739550Z"
    }
   },
   "outputs": [],
   "source": [
    "#news_data.loc[new_candidates[0][1]]['news']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (4) Implement K-nearest neighbor (KNN) search using LSH and compare its performance with linear search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T15:03:40.755091Z",
     "start_time": "2018-05-02T15:03:40.748574Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 19043)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "singnature.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T15:03:40.786674Z",
     "start_time": "2018-05-02T15:03:40.756093Z"
    }
   },
   "outputs": [],
   "source": [
    "class LSH_Knn:\n",
    "    def __init__(self, singnature, n_hyper=10, k=3):\n",
    "        # self._candidates = candidates\n",
    "        self._singnature = singnature.T\n",
    "        self.n_hyper = n_hyper\n",
    "        self.hyper_planes = np.random.randn(self.n_hyper, \n",
    "                                            self._singnature.shape[1])\n",
    "        self.regions = self.get_regions(self._singnature)\n",
    "        self.k = k\n",
    "        \n",
    "    def get_regions(self, singnature):\n",
    "        return (singnature.dot(self.hyper_planes.T) > 0).astype('int')\n",
    "    \n",
    "    def get_distance(self, s1, s2):\n",
    "        intersection = np.logical_and(s1, s2)\n",
    "        union = np.logical_or(s1, s2)\n",
    "        return intersection.sum() / float(union.sum())\n",
    "    \n",
    "    def _get_nn(self, singnature, candidates_idx):\n",
    "        s2 = singnature\n",
    "        temp_candidates_sing = self._singnature[candidates_idx, :]\n",
    "        #print(temp_candidates_sing.shape)\n",
    "        dis = np.apply_along_axis(lambda s1, s2: self.get_distance(s1, s2), \n",
    "                            1, \n",
    "                            temp_candidates_sing,\n",
    "                            s2=s2)\n",
    "        #print(dis)\n",
    "        idx_of_idx = np.argsort(dis)[:self.k]\n",
    "        # print(candidates_idx[idx_of_idx])\n",
    "        return candidates_idx[idx_of_idx]\n",
    "    \n",
    "    def _predict(self, singnature):\n",
    "        r = self.get_regions(singnature)\n",
    "        nn = np.all(r == self.regions, axis=1).astype('int')\n",
    "        candidates_idx = np.argwhere(nn==1).reshape(-1,)\n",
    "        return self._get_nn(singnature, candidates_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T15:03:40.806727Z",
     "start_time": "2018-05-02T15:03:40.788178Z"
    }
   },
   "outputs": [],
   "source": [
    "model = LSH_Knn(singnature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T15:03:40.809736Z",
     "start_time": "2018-05-02T15:03:40.807730Z"
    }
   },
   "outputs": [],
   "source": [
    "N = singnature.T.shape[0]//10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T15:04:01.364870Z",
     "start_time": "2018-05-02T15:03:40.810739Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[LSH Knn] cost 20.547 second in 1904 test data.'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task4_output = ''\n",
    "t1 = time.time()\n",
    "for i in range(N):\n",
    "    idx = model._predict(singnature.T[i])\n",
    "task4_output += ('[LSH Knn] cost {:.3f} second in {} test data.'\n",
    "                 .format(time.time()-t1, N))\n",
    "task4_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T15:04:01.389936Z",
     "start_time": "2018-05-02T15:04:01.365873Z"
    }
   },
   "outputs": [],
   "source": [
    "class MyKNeighborsClassifier:\n",
    "    \n",
    "    def __init__(self, n_neighbors=3, **kwargs):\n",
    "        self._k = n_neighbors\n",
    "        self._X = self._y = None\n",
    "        self.set_params(**kwargs)\n",
    "            \n",
    "    def get_params(self, deep=True):\n",
    "        # suppose this estimator has parameters \"alpha\" and \"recursive\"\n",
    "        return self.__dict__\n",
    "\n",
    "    def set_params(self, **parameters):\n",
    "        for parameter, value in parameters.items():\n",
    "            setattr(self, parameter, value)\n",
    "        return self\n",
    "    \n",
    "    def fit(self, X):\n",
    "        self._X = X.copy()\n",
    "        # self._y = y.copy()\n",
    "        \n",
    "    def get_distance(self, s1, s2):\n",
    "        intersection = np.logical_and(s1, s2)\n",
    "        union = np.logical_or(s1, s2)\n",
    "        return intersection.sum() / float(union.sum())\n",
    "    \n",
    "    def _predict(self, x):\n",
    "        distances = np.apply_along_axis(lambda x1: get_distance(x, x1), \n",
    "                                        1, self._X)\n",
    "        X_candidates = np.argsort(distances)[:self._k]\n",
    "        # y_candidates = self._y[X_candidates]\n",
    "        return X_candidates\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return np.apply_along_axis(lambda x: self._predict(x), 1, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T15:04:01.402469Z",
     "start_time": "2018-05-02T15:04:01.390939Z"
    }
   },
   "outputs": [],
   "source": [
    "model = MyKNeighborsClassifier()\n",
    "model.fit(singnature.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T15:07:57.689860Z",
     "start_time": "2018-05-02T15:04:01.403473Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LSH Knn] cost 20.547 second in 1904 test data.\n",
      "[Linear search Knn] cost 236.282 second in 1904 test data.\n"
     ]
    }
   ],
   "source": [
    "t2 = time.time()\n",
    "for i in range(N):\n",
    "    idx = model._predict(singnature.T[i])\n",
    "task4_output += ('\\n[Linear search Knn] cost {:.3f} second in {} test data.'\n",
    "                 .format(time.time()-t2, N))\n",
    "\n",
    "print(task4_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T15:07:57.697075Z",
     "start_time": "2018-05-02T15:07:57.691060Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('result/task_4.txt', 'w') as f:\n",
    "    f.write(task4_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T15:07:57.703092Z",
     "start_time": "2018-05-02T15:07:57.698078Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost:11.047 min\n"
     ]
    }
   ],
   "source": [
    "print('cost:{:.3f} min'.format((time.time()-t0)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
