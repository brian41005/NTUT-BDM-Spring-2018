{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 103590450 馬茂源 四資四"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-27T10:35:34.687591Z",
     "start_time": "2018-04-27T10:35:33.655246Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "#from nltk import download\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "import string\n",
    "import html\n",
    "import hashlib\n",
    "import re\n",
    "from collections import defaultdict\n",
    "import itertools\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-27T10:35:34.694692Z",
     "start_time": "2018-04-27T10:35:34.690511Z"
    }
   },
   "outputs": [],
   "source": [
    "#download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-27T10:35:34.700042Z",
     "start_time": "2018-04-27T10:35:34.697389Z"
    }
   },
   "outputs": [],
   "source": [
    "t0 = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-27T10:35:34.707068Z",
     "start_time": "2018-04-27T10:35:34.702413Z"
    }
   },
   "outputs": [],
   "source": [
    "if not os.path.exists('result'):\n",
    "    os.mkdir('result')\n",
    "for i in range(1, 5):\n",
    "    dir_ = 'result/task{}'.format(i)\n",
    "    if not os.path.exists(dir_):\n",
    "        os.mkdir(dir_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-27T10:35:34.714196Z",
     "start_time": "2018-04-27T10:35:34.709349Z"
    }
   },
   "outputs": [],
   "source": [
    "file_names = ['./data/reut2-{0:0>3}.sgm'.format(i) for i in range(22)]\n",
    "#file_names = [file_names[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1) Given the Reuters-21578 dataset, please calculate all kshingles and output the set representation of the text dataset as a matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-27T10:35:34.724180Z",
     "start_time": "2018-04-27T10:35:34.716122Z"
    }
   },
   "outputs": [],
   "source": [
    "def parser(file_name):\n",
    "    with open(file_name, 'r', encoding='ISO-8859-1') as f:\n",
    "        file = f.read()\n",
    "    news = []\n",
    "    start = 0\n",
    "    for i in range(len(file)):\n",
    "        if file[i:i+6] == '<BODY>':\n",
    "            start = i+6\n",
    "        elif file[i:i+7] == '</BODY>':\n",
    "            n = file[start:i].replace('\\n', ' ')\n",
    "            n = n.replace('REUTER &#3;', '')\n",
    "            news.append(n)\n",
    "    return news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-27T10:35:45.538834Z",
     "start_time": "2018-04-27T10:35:34.728293Z"
    }
   },
   "outputs": [],
   "source": [
    "news = []\n",
    "for i in file_names:\n",
    "    each_news = parser(i) \n",
    "    news.extend(each_news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-27T10:35:45.552022Z",
     "start_time": "2018-04-27T10:35:45.540825Z"
    }
   },
   "outputs": [],
   "source": [
    "len(news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-27T10:35:45.560894Z",
     "start_time": "2018-04-27T10:35:45.555762Z"
    }
   },
   "outputs": [],
   "source": [
    "news_data = pd.DataFrame(data=news, columns=['news'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-27T10:35:45.591011Z",
     "start_time": "2018-04-27T10:35:45.562641Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "news_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-27T10:35:45.599188Z",
     "start_time": "2018-04-27T10:35:45.592777Z"
    }
   },
   "outputs": [],
   "source": [
    "def tokenizer(text):\n",
    "    strip_chars = '.' + ' –…' + string.punctuation\n",
    "    text = html.unescape(text)\n",
    "    text = text.lower()\n",
    "    text = text.strip(strip_chars)\n",
    "    text = text.replace('reuter', '')\n",
    "    text = re.sub(re.compile('<.*?>'), '', text)\n",
    "    return re.findall(r'\\w+', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-27T10:35:45.606109Z",
     "start_time": "2018-04-27T10:35:45.600594Z"
    }
   },
   "outputs": [],
   "source": [
    "test_news = news_data['news'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-27T10:35:45.611404Z",
     "start_time": "2018-04-27T10:35:45.608409Z"
    }
   },
   "outputs": [],
   "source": [
    "#tokenizer(test_news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-27T10:35:47.703322Z",
     "start_time": "2018-04-27T10:35:45.613127Z"
    }
   },
   "outputs": [],
   "source": [
    "news_data['news_token'] = news_data.apply(lambda x: tokenizer(x['news']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-27T10:35:47.710252Z",
     "start_time": "2018-04-27T10:35:47.705137Z"
    }
   },
   "outputs": [],
   "source": [
    "#news_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-27T10:35:47.716432Z",
     "start_time": "2018-04-27T10:35:47.712520Z"
    }
   },
   "outputs": [],
   "source": [
    "def k_shingle(text, k):\n",
    "    string = ' '.join(text)\n",
    "    shingles = set([])\n",
    "    for i in range(len(string)-k + 1):\n",
    "        shingles.add(string[i:i+k])\n",
    "    return (shingles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-27T10:35:53.248086Z",
     "start_time": "2018-04-27T10:35:47.720372Z"
    }
   },
   "outputs": [],
   "source": [
    "news_data['news_token'] = news_data['news_token'].apply(lambda x: k_shingle(x, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-27T10:35:54.201636Z",
     "start_time": "2018-04-27T10:35:53.250232Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "shingles = set([])\n",
    "for s in news_data['news_token'].values:\n",
    "    shingles |= s\n",
    "shingles = list(shingles)\n",
    "len(shingles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-27T10:35:54.295227Z",
     "start_time": "2018-04-27T10:35:54.203963Z"
    }
   },
   "outputs": [],
   "source": [
    "shingles_dict_ = {s:i for i, s in enumerate(shingles)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-27T10:35:54.301450Z",
     "start_time": "2018-04-27T10:35:54.297512Z"
    }
   },
   "outputs": [],
   "source": [
    "def encode_shingles(row, shingles_dict_):\n",
    "    v = np.zeros(len(shingles_dict_), dtype='int')\n",
    "    idx_list = [shingles_dict_[r] for r in row] \n",
    "    v[idx_list] = 1\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-27T10:36:17.215673Z",
     "start_time": "2018-04-27T10:35:54.304038Z"
    }
   },
   "outputs": [],
   "source": [
    "news_data['shingles'] = news_data['news_token'].apply(encode_shingles, args=(shingles_dict_,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-04-27T10:35:33.761Z"
    }
   },
   "outputs": [],
   "source": [
    "output_shingles = np.array(news_data['shingles'].tolist()).T\n",
    "output_shingles.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-04-27T10:35:33.764Z"
    }
   },
   "outputs": [],
   "source": [
    "#np.savetxt(\"task_1.csv\", output_shingles, delimiter=\",\",  fmt='%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2) Given the set representation, compute the minhash signatures of all documents using MapReduce."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-04-27T10:35:33.823Z"
    }
   },
   "outputs": [],
   "source": [
    "news_shingles = output_shingles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-04-27T10:35:33.826Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_prime(greater_than):\n",
    "    \n",
    "    def is_prime(n):\n",
    "        if n % 2 == 0 and n > 2: \n",
    "            return False\n",
    "        return all(n % i for i in range(3, int(np.sqrt(n)) + 1, 2))\n",
    "    is_p = False\n",
    "    \n",
    "    \n",
    "    \n",
    "    while not is_p:\n",
    "        greater_than += 1\n",
    "        is_p = is_prime(greater_than)\n",
    "        \n",
    "    return greater_than"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-04-27T10:35:33.829Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_hash_func_list(n, k=100):\n",
    "    p = get_prime(n)\n",
    "    func_list = []\n",
    "    for a, b in zip(np.random.randint(0, n, size=k),\n",
    "                   np.random.randint(0, n, size=k)):\n",
    "        func_list.append(lambda x, a=a,b=b,p=p,n=n: ((a*x+b)%p)%n)\n",
    "    return np.array(func_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-04-27T10:35:33.832Z"
    }
   },
   "outputs": [],
   "source": [
    "def one_pass_minhashing(shingles, k=100):\n",
    "    n = shingles.shape[0]\n",
    "    hash_list = get_hash_func_list(n, k=k)\n",
    "    singnature = np.full((k, shingles.shape[1]), fill_value=np.inf)\n",
    "    \n",
    "    for i in range(n):\n",
    "        hash_value = np.array([h(i) for h in hash_list])\n",
    "\n",
    "        for j, c in enumerate(shingles[i, :] == 1):\n",
    "            if c:\n",
    "                mask = singnature[:, j] > hash_value\n",
    "                singnature[:, j][mask] = hash_value[mask]\n",
    "            \n",
    "    return singnature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-04-27T10:35:33.835Z"
    }
   },
   "outputs": [],
   "source": [
    "test_input = np.array([[1,0,1,0],\n",
    "                       [1,0,0,1],\n",
    "                       [0,1,0,1],\n",
    "                       [0,1,0,1],\n",
    "                       [0,1,0,1],\n",
    "                       [1,0,1,0],\n",
    "                       [1,0,1,0]])\n",
    "test_singnature = one_pass_minhashing(test_input, k=6)\n",
    "test_singnature.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-04-27T10:35:33.836Z"
    }
   },
   "outputs": [],
   "source": [
    "singnature = one_pass_minhashing(news_shingles, k=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-04-27T10:35:33.838Z"
    }
   },
   "outputs": [],
   "source": [
    "singnature.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-04-27T10:35:33.840Z"
    }
   },
   "outputs": [],
   "source": [
    "#np.savetxt(\"task_2.csv\", singnature, delimiter=\",\",  fmt='%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (3) Implement the LSH algorithm by MapReduce and output the resulting candidate pairs of similar documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-04-27T10:35:33.897Z"
    }
   },
   "outputs": [],
   "source": [
    "hashlib.sha512().block_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-04-27T10:35:33.899Z"
    }
   },
   "outputs": [],
   "source": [
    "def LSH(singnature, b=2):\n",
    "    buckets = [defaultdict(set) for i in range(b)]\n",
    "    k = singnature.shape[0]\n",
    "    r = k // b\n",
    "    for i, doc in enumerate(singnature.T):\n",
    "        x = np.array2string(doc.astype('int'), separator='', precision=0)\n",
    "        for j, start_idx in enumerate(range(0, k, r)):\n",
    "            #print(j, j+r)\n",
    "            key = hashlib.sha512(x[start_idx:start_idx+r].encode()).hexdigest()\n",
    "            buckets[j][key].add(i)\n",
    "    return buckets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-04-27T10:35:33.901Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_candidate(buckets):\n",
    "    candidates = set([])\n",
    "    for bucket in buckets:\n",
    "        for k, item in bucket.items():\n",
    "            if len(item) > 1:\n",
    "                pairs = itertools.combinations(item, 2)\n",
    "                for p in pairs:\n",
    "                    candidates.add(p)\n",
    "\n",
    "    return candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-04-27T10:35:33.904Z"
    }
   },
   "outputs": [],
   "source": [
    "# bucket = LSH(test_singnature, b=2)\n",
    "# bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-04-27T10:35:33.905Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "buckets = LSH(singnature, b=20)\n",
    "candidates = get_candidate(buckets)\n",
    "candidates = list(candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-04-27T10:35:33.908Z"
    }
   },
   "outputs": [],
   "source": [
    "len(candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-04-27T10:35:33.910Z"
    }
   },
   "outputs": [],
   "source": [
    "new_candidates = []\n",
    "for d_id_1, d_id_2 in candidates:\n",
    "    intersection = np.logical_and(singnature[:, d_id_1],\n",
    "                                  singnature[:, d_id_2])\n",
    "    union = np.logical_or(singnature[:, d_id_1],\n",
    "                          singnature[:, d_id_2])\n",
    "    s = intersection.sum() / float(union.sum())\n",
    "    if s >= 0.8:\n",
    "        new_candidates.append((d_id_1, d_id_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-04-27T10:35:33.911Z"
    }
   },
   "outputs": [],
   "source": [
    "len(new_candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-04-27T10:35:33.913Z"
    }
   },
   "outputs": [],
   "source": [
    "new_candidates[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-04-27T10:35:33.916Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "news_data.loc[new_candidates[0][0]]['news']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-04-27T10:35:33.917Z"
    }
   },
   "outputs": [],
   "source": [
    "news_data.loc[new_candidates[0][1]]['news']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (4) Implement K-nearest neighbor (KNN) search using LSH and compare its performance with linear search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-04-27T10:35:33.971Z"
    }
   },
   "outputs": [],
   "source": [
    "print('cost:{:.3f} min'.format((time.time()-t0)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
